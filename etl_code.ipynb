{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Transform Load (ETL) Lab\n",
    "\n",
    "Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "Read CSV and JSON file types.\n",
    "\n",
    "Extract data from the above file types.\n",
    "\n",
    "Transform data.\n",
    "\n",
    "Save the transformed data in a ready-to-load format which data engineers can use to load into an RDBMS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required modules and functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob                         # this module helps in selecting files \n",
    "import pandas as pd                 # this module helps in processing CSV files\n",
    "import xml.etree.ElementTree as ET  # this module helps in processing XML files.\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_file    = \"temp.tmp\"               # file used to store all extracted data\n",
    "log_file    = \"log_file.txt\"            # all event logs will be stored in this file\n",
    "target_file = \"transformed_data.csv\"   # file where transformed data is stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACT\n",
    "\n",
    "CSV Extract Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(file_to_process): \n",
    "    dataframe = pd.read_csv(file_to_process) \n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON Extract Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_json(file_to_process): \n",
    "    dataframe = pd.read_json(file_to_process, lines=True) \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XML Extract Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_xml(file_to_process): \n",
    "    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"]) \n",
    "    tree = ET.parse(file_to_process) \n",
    "    root = tree.getroot() \n",
    "    for person in root: \n",
    "        name = person.find(\"name\").text \n",
    "        height = float(person.find(\"height\").text) \n",
    "        weight = float(person.find(\"weight\").text) \n",
    "        dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True) \n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(): \n",
    "    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data \n",
    "     \n",
    "    # process all csv files \n",
    "    for csvfile in glob.glob(\"*.csv\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True) \n",
    "         \n",
    "    # process all json files \n",
    "    for jsonfile in glob.glob(\"*.json\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_json(jsonfile))], ignore_index=True) \n",
    "     \n",
    "    # process all xml files \n",
    "    for xmlfile in glob.glob(\"*.xml\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_xml(xmlfile))], ignore_index=True) \n",
    "         \n",
    "    return extracted_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform\n",
    "The transform function does the following tasks.\n",
    "\n",
    "1. Convert height which is in inches to millimeter\n",
    "2. Convert weight which is in pounds to kilograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "        #Convert height which is in inches to millimeter\n",
    "        #Convert the datatype of the column into float\n",
    "        #data.height = data.height.astype(float)\n",
    "        #Convert inches to meters and round off to two decimals(one inch is 0.0254 meters)\n",
    "        data['height'] = round(data.height * 0.0254,2)\n",
    "        \n",
    "        #Convert weight which is in pounds to kilograms\n",
    "        #Convert the datatype of the column into float\n",
    "        #data.weight = data.weight.astype(float)\n",
    "        #Convert pounds to kilograms and round off to two decimals(one pound is 0.45359237 kilograms)\n",
    "        data['weight'] = round(data.weight * 0.45359237,2)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(target_file, transformed_data):\n",
    "    transformed_data.to_csv(target_file)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message):\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second\n",
    "    now = datetime.now() # get current timestamp\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"log_file.txt\",\"a\") as f:\n",
    "        f.write(timestamp + ',' + message + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running ETL Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data\n",
      "    name height weight  Unnamed: 0        Country  GDP_USD_billions Currency  \\\n",
      "0    NaN    NaN    NaN         0.0  United States          26854.60      NaN   \n",
      "1    NaN    NaN    NaN         1.0          China          19373.59      NaN   \n",
      "2    NaN    NaN    NaN         2.0          Japan           4409.74      NaN   \n",
      "3    NaN    NaN    NaN         3.0        Germany           4308.85      NaN   \n",
      "4    NaN    NaN    NaN         4.0          India           3736.88      NaN   \n",
      "..   ...    ...    ...         ...            ...               ...      ...   \n",
      "189  NaN    NaN    NaN       189.0          Nauru              0.15      NaN   \n",
      "190  NaN    NaN    NaN       190.0         Tuvalu              0.06      NaN   \n",
      "191  NaN    NaN    NaN         NaN            NaN               NaN      EUR   \n",
      "192  NaN    NaN    NaN         NaN            NaN               NaN      GBP   \n",
      "193  NaN    NaN    NaN         NaN            NaN               NaN      INR   \n",
      "\n",
      "      Rate  \n",
      "0      NaN  \n",
      "1      NaN  \n",
      "2      NaN  \n",
      "3      NaN  \n",
      "4      NaN  \n",
      "..     ...  \n",
      "189    NaN  \n",
      "190    NaN  \n",
      "191   0.93  \n",
      "192   0.80  \n",
      "193  82.95  \n",
      "\n",
      "[194 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Log the initialization of the ETL process \n",
    "log_progress(\"ETL Job Started\") \n",
    " \n",
    "# Log the beginning of the Extraction process \n",
    "log_progress(\"Extract phase Started\") \n",
    "extracted_data = extract() \n",
    " \n",
    "# Log the completion of the Extraction process \n",
    "log_progress(\"Extract phase Ended\") \n",
    " \n",
    "# Log the beginning of the Transformation process \n",
    "log_progress(\"Transform phase Started\") \n",
    "transformed_data = transform(extracted_data) \n",
    "print(\"Transformed Data\") \n",
    "print(transformed_data) \n",
    " \n",
    "# Log the completion of the Transformation process \n",
    "log_progress(\"Transform phase Ended\") \n",
    " \n",
    "# Log the beginning of the Loading process \n",
    "log_progress(\"Load phase Started\") \n",
    "load_data(target_file,transformed_data) \n",
    " \n",
    "# Log the completion of the Loading process \n",
    "log_progress(\"Load phase Ended\") \n",
    " \n",
    "# Log the completion of the ETL process \n",
    "log_progress(\"ETL Job Ended\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
